{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Entities\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from processing.RL.DDPG.ddpg import DDPG\n",
    "from processing.robotics.arm_propagator import ArmPropagator, ElectromagnetEndEffector, RevoluteJoint\n",
    "from processing.system_animation import animate_system\n",
    "from processing.utilities.entities import Cylinder\n",
    "\n",
    "# Attitude\n",
    "from processing.attitude.attitude_propagator import AttitudePropagator\n",
    "from processing.attitude.torques.base import TorqueObject\n",
    "from processing.attitude.torques.eddy_current import EddyCurrentTorque\n",
    "\n",
    "# Environment\n",
    "from propagator.bin.environment import Environment"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_step(t: float, prop: list, at: AttitudePropagator, ar: ArmPropagator, tau: np.ndarray):\n",
    "    # TODO: Move to within single classes\n",
    "    # Convert to numpy\n",
    "    prop = np.array(prop)\n",
    "\n",
    "    # Save arm\n",
    "    if ar._timestamps is None:\n",
    "        ar._timestamps = np.array([t])\n",
    "        ar._prop_sol = prop[0:12].reshape(-1, 1)\n",
    "        ar.joint_torques = tau.reshape(-1, 1)\n",
    "    else:\n",
    "        ar._timestamps = np.hstack((ar._timestamps, np.array([t])))\n",
    "        ar._prop_sol = np.hstack((ar._prop_sol, prop[0:12].reshape(-1, 1)))\n",
    "        ar.joint_torques = np.hstack((ar.joint_torques, tau.reshape(-1, 1)))\n",
    "\n",
    "    # Save end effector results\n",
    "    ar.end_effector._timestamps = ar._timestamps\n",
    "    if ar.end_effector.locations is None:\n",
    "        ar.end_effector.locations = prop[19:22].reshape(-1, 1)\n",
    "        ar.end_effector.poses = prop[22:25].reshape(-1, 1)\n",
    "    else:\n",
    "        ar.end_effector.locations = np.hstack((ar.end_effector.locations, prop[19:22].reshape(-1, 1)))\n",
    "        ar.end_effector.poses = np.hstack((ar.end_effector.poses, prop[22:25].reshape(-1, 1)))\n",
    "\n",
    "    # Save attitude\n",
    "    at._timestamps = ar._timestamps\n",
    "    if at._prop_sol is None:\n",
    "        at._prop_sol = prop[12:19].reshape(-1, 1)\n",
    "    else:\n",
    "        at._prop_sol = np.hstack((at._prop_sol, prop[12:19].reshape(-1, 1)))\n",
    "\n",
    "    return"
   ],
   "id": "178c8fb19ff71d49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# System setup",
   "id": "fd60d64ab7b2489a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate debris\n",
    "debris = Cylinder(\n",
    "    mass=950.0,\n",
    "    radius=2.5,\n",
    "    height=5.0,\n",
    "    thickness=0.1,\n",
    "    sigma=35000000.0\n",
    ")\n",
    "\n",
    "# Generate robotic arms (UR10 standard)\n",
    "# Joints\n",
    "scale = 10\n",
    "joints = [\n",
    "    RevoluteJoint(0, scale*0.1807, np.pi/2),\n",
    "    RevoluteJoint(scale*-0.6127, 0, 0),\n",
    "    RevoluteJoint(scale*-0.57155, 0, 0),\n",
    "    RevoluteJoint(0, scale*0.17415, np.pi/2),\n",
    "    RevoluteJoint(0, scale*0.11985, -np.pi/2),\n",
    "    RevoluteJoint(0, scale*0.11655, 0)\n",
    "]\n",
    "\n",
    "# End effector\n",
    "electromagnet: ElectromagnetEndEffector = ElectromagnetEndEffector(\n",
    "    n_turns=500.0,\n",
    "    radius=1.0,\n",
    "    current=50.0\n",
    ")\n",
    "\n",
    "# External moments\n",
    "# Eddy current\n",
    "eddy: TorqueObject = EddyCurrentTorque(\n",
    "    entity=debris,\n",
    "    chaser_w0=[0.0, 0.0, 0.0],\n",
    "    electromagnets=[electromagnet]\n",
    ")\n",
    "\n",
    "# Save attitude results\n",
    "attitude = AttitudePropagator(entity=debris, M_ext=eddy)\n",
    "\n",
    "# Save robotic arm results\n",
    "base_offset = np.array([10, 0, 5])\n",
    "arm = ArmPropagator(joints=joints, end_effector=electromagnet, base_offset=base_offset)"
   ],
   "id": "3850ece381a2c34d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environment Setup",
   "id": "d6f6ee2e69c16107"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set propagation settings\n",
    "t_step = 0.1  # Propagation time step [s]\n",
    "\n",
    "# Set initial conditions\n",
    "y0_arm = [\n",
    "    0.0, -0.7, -0.3, 0.0, 0.0, 0.0,   # Initial joint angles\n",
    "    0.0, 0.0, 0.0, 0.0, 0.0, 0.0      # Initial joint velocities\n",
    "]\n",
    "y0_debris = [\n",
    "    0.1, 0.2, 0.0,                    # Initial debris angular velocity\n",
    "    0.0, 0.0, 0.0, 1.0                # Initial debris quaternions\n",
    "]   \n",
    "\n",
    "# Initialize environment\n",
    "env = Environment(\n",
    "    y0_arm + y0_debris,                   # Initial conditions\n",
    "    debris.Ixx,                           # Debris Ixx\n",
    "    debris.Iyy,                           # Debris Iyy\n",
    "    debris.Izz,                           # Debris Izz\n",
    "    debris.radius,                        # Debris cylinder radius\n",
    "    debris.height,                        # Debris cylinder height \n",
    "    debris.thickness,                     # Debris cylinder thickness\n",
    "    debris.sigma,                         # Debris conductivity\n",
    "    electromagnet.n_turns,                # Coil number of turns\n",
    "    electromagnet.current,                # Coil current\n",
    "    electromagnet.radius,                 # Coil radius\n",
    "    arm.base_offset_x,                    # Arm base x-offset\n",
    "    arm.base_offset_y,                    # Arm base y-offset\n",
    "    arm.base_offset_z,                    # Arm base z-offset\n",
    "    scale,                                # Arm scaling factor\n",
    "    arm.dh_a,                             # Arm joint a parameters\n",
    "    arm.dh_d,                             # Arm joint d parameters\n",
    "    arm.dh_alpha                          # Arm joint alpha parameters\n",
    "    )"
   ],
   "id": "c1025c7fd7e4c9ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DDPG: Training\n",
    "\n",
    "Define stopping criteria: collision or completed detumbling"
   ],
   "id": "85718e3c628f77a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define safe sphere for collision check\n",
    "safe_sphere: float = max(debris.height/2, debris.radius) + 0.5  # [m]\n",
    "\n",
    "# Define detumbling threshold\n",
    "detumbling_threshold: float = 0.01  # [rad/s]\n",
    "\n",
    "# Define max joint range and angular velocity\n",
    "max_range: float = np.deg2rad(np.array([360, 360, 360, 360, 360, 360]))      # [deg]\n",
    "max_joint_vel: float = np.deg2rad(np.array([120, 120, 180, 180, 180, 180]))  # [deg/s]\n",
    "\n",
    "# Max torque\n",
    "max_torques: np.ndarray = np.array([5000, 3000, 1000, 100, 1, 0.0001])"
   ],
   "id": "e4b3a2412318d2ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define reward and end checks function",
   "id": "7a4a54b99c7c46fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_step(step_ret, prev_state):\n",
    "    # Convert to numpy\n",
    "    step_ret = np.array(step_ret)\n",
    "    state = np.array([*step_ret[:15], *step_ret[19:]])\n",
    "    \n",
    "    # Init \"done\" and \"reward\"\n",
    "    done = 0  # \"done\" normally negative\n",
    "    reward = 0\n",
    "    \n",
    "    # Check: collision with safe sphere\n",
    "    for i in range(len(arm.joints) + 1):\n",
    "        pos: np.ndarray = arm.get_joint_position(step_ret[0:6], i)\n",
    "        if np.linalg.norm(pos) <= safe_sphere:\n",
    "            done = 1\n",
    "            reward -= 10\n",
    "            print(\"Collision\", reward)\n",
    "            return state, reward, done  # Collision happened, simulation over\n",
    "            \n",
    "    # Check: tumbling rates below certain threshold\n",
    "    ang_vels: np.ndarray = step_ret[12:15]\n",
    "    if np.all(np.abs(ang_vels) <= detumbling_threshold):\n",
    "        done = 1\n",
    "        # reward += 25\n",
    "        print(\"Detumbling\", reward)\n",
    "        return state, reward, done  # Detumbling completed, simulation over\n",
    "    \n",
    "    # Penalty: end effector pointing away\n",
    "    ee_loc: np.ndarray = -step_ret[19:22]\n",
    "    ee_pos: np.ndarray = step_ret[22:25]\n",
    "    angle = np.arccos(np.dot(ee_loc / np.linalg.norm(ee_loc), ee_pos / np.linalg.norm(ee_pos)))\n",
    "    reward -= abs(angle)\n",
    "    \n",
    "    # Check: joint angles beyond a certain threshold\n",
    "    if np.any(np.abs(step_ret[6:12]) > max_joint_vel):\n",
    "        reward -= 5\n",
    "        return state, reward, done  # Joint angular velocity too high, simulation over\n",
    "    \n",
    "    \"\"\"# Check: range beyond a certain value\n",
    "    if np.any(np.abs(step_ret[:6]) > max_range):\n",
    "        reward -= 5\n",
    "        return step_ret, reward, done  # Joint max range too high, simulation over\n",
    "\n",
    "    # Reward: Detumbling rate\n",
    "    dwx = abs(step_ret[12]) - abs(prev_state[12]) / t_step\n",
    "    dwy = abs(step_ret[13]) - abs(prev_state[13]) / t_step\n",
    "    dwz = abs(step_ret[14]) - abs(prev_state[14]) / t_step\n",
    "    \n",
    "    if sum(1 for grad in [dwx, dwy, dwz] if grad < 0) < 2:\n",
    "        reward -= 0.25  # no component decreasing\n",
    "    \"\"\"\n",
    "    \n",
    "    return state, reward, done"
   ],
   "id": "aeea34831961c979",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train setup",
   "id": "c4ce2ad218a248d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Init torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define different parameters for training the agent\n",
    "max_episode = 200\n",
    "max_time_steps = 1000\n",
    "ep_r = 0\n",
    "total_step = 0\n",
    "score_hist = []\n",
    "\n",
    "# For reproducibility\n",
    "# env.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)\n",
    "\n",
    "# Environment action ans states\n",
    "state_dim = 21\n",
    "action_dim = 6\n",
    "min_Val = torch.tensor(1e-7).float().to(device)\n",
    "\n",
    "# Create a DDPG instance\n",
    "agent = DDPG(state_dim, action_dim, hidden_actor=128, hidden_critic=128)"
   ],
   "id": "ff8833f5625b2263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training loop",
   "id": "73c3299f8caed309"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the agent for max_episodes\n",
    "for i in range(max_episode):\n",
    "    total_reward = 0\n",
    "    step = 0\n",
    "\n",
    "    # Reset environment\n",
    "    state = np.array(env.current_state()[-1])[:state_dim]  # discard time\n",
    "    for _ in range(max_time_steps):\n",
    "        # Get action\n",
    "        noise = max_torques * np.random.normal(0, 1, size=action_dim)\n",
    "        action = (agent.select_action(state) + noise).clip(-max_torques, max_torques) # Noise and clip\n",
    "        # action += ou_noise.sample()\n",
    "\n",
    "        # Perform step\n",
    "        t, step_ret = env.step(t_step=t_step, action=list(action))\n",
    "        next_state, reward, done = evaluate_step(step_ret, state)\n",
    "\n",
    "        # Retrieve reward\n",
    "        total_reward += reward\n",
    "        agent.replay_buffer.push((state, next_state, action, reward, done))\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "        step += 1\n",
    "        \n",
    "    del env\n",
    "    env = Environment(\n",
    "    y0_arm + y0_debris,                   # Initial conditions\n",
    "    debris.Ixx,                           # Debris Ixx\n",
    "    debris.Iyy,                           # Debris Iyy\n",
    "    debris.Izz,                           # Debris Izz\n",
    "    debris.radius,                        # Debris cylinder radius\n",
    "    debris.height,                        # Debris cylinder height \n",
    "    debris.thickness,                     # Debris cylinder thickness\n",
    "    debris.sigma,                         # Debris conductivity\n",
    "    electromagnet.n_turns,                # Coil number of turns\n",
    "    electromagnet.current,                # Coil current\n",
    "    electromagnet.radius,                 # Coil radius\n",
    "    arm.base_offset_x,                    # Arm base x-offset\n",
    "    arm.base_offset_y,                    # Arm base y-offset\n",
    "    arm.base_offset_z,                    # Arm base z-offset\n",
    "    scale,                                # Arm scaling factor\n",
    "    arm.dh_a,                             # Arm joint a parameters\n",
    "    arm.dh_d,                             # Arm joint d parameters\n",
    "    arm.dh_alpha                          # Arm joint alpha parameters\n",
    "    )\n",
    "\n",
    "    score_hist.append(total_reward)\n",
    "    total_step += step + 1\n",
    "    print(\"Episode: {} \\t Time: {:0.2f}s \\t Total Reward: {:0.2f}\".format(i, t, total_reward))\n",
    "    agent.update(update_iteration=200, gamma=0.99, tau=0.001, batch_size=32)\n",
    "    if i % 10 == 0:\n",
    "        agent.save(\"./\")"
   ],
   "id": "315cfe993e16e84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "def plot_learning_curve(x, scores):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title(f'Running average of previous {max_episode} scores')\n",
    "\n",
    "x = [i+1 for i in range(len(score_hist))]\n",
    "plot_learning_curve(x, score_hist)"
   ],
   "id": "1b311b3805fd3bcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DDPG: Testing",
   "id": "87659aa2930d5d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_iteration=200\n",
    "  \n",
    "for t in range(test_iteration):\n",
    "    # Get action\n",
    "    action = (agent.select_action(state)).clip(-max_torques, max_torques) # Noise and clip\n",
    "\n",
    "    # Perform step\n",
    "    _, step_ret = env.step(t_step=t_step, action=list(action))\n",
    "    next_state, reward, done = evaluate_step(step_ret, state)\n",
    "    save_step(t, step_ret, attitude, arm, action)\n",
    "\n",
    "    ep_r += reward\n",
    "    if done: \n",
    "        print(\"reward{}\".format(reward))\n",
    "        print(\"Episode \\t{}, the episode reward is \\t{:0.2f}\".format(t, ep_r))\n",
    "        ep_r = 0\n",
    "        break\n",
    "    state = next_state"
   ],
   "id": "691e2c8adf6bc8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = [i+1 for i in range(arm.joint_torques.shape[-1])]\n",
    "plt.title(f'Torques evolution')\n",
    "plt.grid(True)\n",
    "plt.plot(x, arm.joint_torques.T)"
   ],
   "id": "eb885bd8a71cbdd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "attitude.plot([\"angular_velocity\", \"quaternions\", \"energy\", \"euler_angles\"])",
   "id": "3dd5bb7ac259a1fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arm.plot()",
   "id": "8a644068f537b694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "animate_system(\n",
    "    t=attitude.t,\n",
    "    q=attitude.q,\n",
    "    eu=attitude.euler_angles,\n",
    "    h=debris.height,\n",
    "    r=debris.radius,\n",
    "    dpi=300,\n",
    "    arms=[arm],\n",
    "    dh_par=joints\n",
    ")"
   ],
   "id": "df30b0cf72174617",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
